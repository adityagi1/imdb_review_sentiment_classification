{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:30px\"><b> IMDB Review Sentiment Classification </b></p>\n",
    "<p style=\"font-size:20px\"> by Aditya Tyagi </p>\n",
    "\n",
    "\n",
    "**Problem Statement**: \n",
    "\n",
    "Perform Sentiment analysis on IMDB Dataset of 50K Movie Reviews. Do a thorough Exploratory Data Analysis of the dataset and report the final performance metrics for your approach. Suggest ways in which you can improve the model.\n",
    "\n",
    "\n",
    "**Tips**\n",
    "- Ask yourself why would they have selected this problem for the challenge? What are some gotchas in this domain I should know about?\n",
    "- What is the highest level of accuracy that others have achieved with this dataset or similar problems / datasets ?\n",
    "- What types of visualizations will help me grasp the nature of the problem / data?\n",
    "- What feature engineering might help improve the signal?\n",
    "- Which modeling techniques are good at capturing the types of relationships I see in this data?\n",
    "- Now that I have a model, how can I be sure that I didn't introduce a bug in the code? If results are too good to be true, they probably are!\n",
    "- What are some of the weaknesses of the model and and how can the model be improved with additional work\n",
    "\n",
    "**Key Takeaway**\n",
    "\n",
    "- A logistic regression model with the below parameters and a tfidf unigram feature set performs best. It has a accuracy of 0.875 (train=0.896), and an F1 score of 0.876 (train=0.898). \n",
    "    * C=1, penalty='l1' || tfidf_1\n",
    "- A supplementary LDA model then identifies the key topics driving each sentiment prediction. One appropriate number of topics to look for is 3. \n",
    "\n",
    "\n",
    "**Approach**\n",
    "\n",
    "My general approach is to take construct three sets of features (tfidf, doc2vec, glove), and then try out each of them with an ML model to see which combination performs best. Finally, I determine a business use case for my project, by implementing an LDA approach for predictions generated by the sentiment classification model. \n",
    "\n",
    "1. Parse data\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Engineering\n",
    "    * tfidf representation\n",
    "    * doc2vec embedding\n",
    "    * glove embedding\n",
    "4. Model Development\n",
    "    * Logistic Regression \n",
    "    * Support Vector Machine\n",
    "    * k-Nearest Neighbor Classifier\n",
    "    * Random Forest\n",
    "    * Gradient Boosting classifier\n",
    "5. Model Interpretation\n",
    "    * Plotting ROC curve and optimal decision threshold identification\n",
    "    * Identification of coefficients\n",
    "6. Business Context\n",
    "    * Segment predictiions by sentiment\n",
    "    * LDA Topic Model\n",
    "7. Next Steps\n",
    "\n",
    "\n",
    "**Background & Benchmarking**\n",
    "\n",
    "In the paper accompanying the dataset, Pang et al obtain an accuracy of ~87% on this dataset, using a BoW approach and optimizations introduced in their paper. \n",
    "\n",
    "# Parse Data\n",
    "\n",
    "We begin by parsing the data into a Pandas dataframe, and persisting a a .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_PATH = \"aclImdb_v1.tar/aclImdb/train/pos\"\n",
    "file_names = os.listdir(\"aclImdb_v1.tar/aclImdb/train/pos\")\n",
    "\n",
    "\n",
    "def read_data(base_path, file_names, label):\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        full_path = os.path.join(base_path, file_name) \n",
    "        with open(full_path, 'r', encoding='utf8') as f:\n",
    "            review_id = file_name.split(\".\")[0].split(\"_\")[0]\n",
    "            review_rating = file_name.split(\".\")[0].split(\"_\")[1]\n",
    "            review_txt = f.read()\n",
    "            review = {\n",
    "                'id': review_id,\n",
    "                'rating': review_rating,\n",
    "                'text': review_txt,\n",
    "                'label': label\n",
    "            }\n",
    "        data.append(review)\n",
    "    return data\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = read_data(base_path=\"aclImdb_v1.tar/aclImdb/train/pos\", \n",
    "                      file_names=os.listdir(\"aclImdb_v1.tar/aclImdb/train/pos\"),\n",
    "                      label='pos')\n",
    "train_neg = read_data(base_path=\"aclImdb_v1.tar/aclImdb/train/neg\", \n",
    "                      file_names= os.listdir(\"aclImdb_v1.tar/aclImdb/train/neg\"),\n",
    "                      label='neg')\n",
    "train = train_pos + train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = read_data(base_path=\"aclImdb_v1.tar/aclImdb/test/pos\", \n",
    "                    file_names=os.listdir(\"aclImdb_v1.tar/aclImdb/test/pos\"),\n",
    "                    label='pos')\n",
    "test_neg = read_data(base_path=\"aclImdb_v1.tar/aclImdb/test/neg\", \n",
    "                    file_names=os.listdir(\"aclImdb_v1.tar/aclImdb/test/neg\"),\n",
    "                    label='neg')\n",
    "test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training positive examples: 12500\n",
      "No. of training negative examples: 12500\n",
      "Total training examples: 25000\n",
      "-------------\n",
      "No. of test positive examples: 12500\n",
      "No. of test negative examples: 12500\n",
      "Total test examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of training positive examples: {len(train_pos)}\")\n",
    "print(f\"No. of training negative examples: {len(train_neg)}\")\n",
    "print(f\"Total training examples: {len(train)}\")\n",
    "print(\"-------------\")\n",
    "print(f\"No. of test positive examples: {len(test_pos)}\")\n",
    "print(f\"No. of test negative examples: {len(test_neg)}\")\n",
    "print(f\"Total test examples: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store as a pandas df\n",
    "train = pd.DataFrame({'id': [review['id'] for review in train], \n",
    "         'text': [review['text'] for review in train],\n",
    "         'rating': [review['rating'] for review in train],\n",
    "         'label': [review['label'] for review in train]\n",
    "        })\n",
    "\n",
    "test = pd.DataFrame({'id': [review['id'] for review in test], \n",
    "         'text': [review['text'] for review in test],\n",
    "         'rating': [review['rating'] for review in test],\n",
    "         'label': [review['label'] for review in test]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text rating label\n",
       "0      0  Bromwell High is a cartoon comedy. It ran at t...      9   pos\n",
       "1  10000  Homelessness (or Houselessness as George Carli...      8   pos\n",
       "2  10001  Brilliant over-acting by Lesley Ann Warren. Be...     10   pos\n",
       "3  10002  This is easily the most underrated film inn th...      7   pos\n",
       "4  10003  This is not the typical Mel Brooks film. It wa...      8   pos"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persist as .csv\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv's back into pandas dataframes\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploratory Data Analysis\n",
    "\n",
    "## Visualizations\n",
    "During the EDA phase, we construct various plots and visualizations to aid our analysis of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rating', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of ratings - extreme ratings are most common (this is good)\n",
    "sns.countplot(train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#labels are exactly balanced; this is fantastic!\n",
    "sns.countplot(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  rating label  \\\n",
       "0      0  Bromwell High is a cartoon comedy. It ran at t...       9   pos   \n",
       "1  10000  Homelessness (or Houselessness as George Carli...       8   pos   \n",
       "2  10001  Brilliant over-acting by Lesley Ann Warren. Be...      10   pos   \n",
       "3  10002  This is easily the most underrated film inn th...       7   pos   \n",
       "4  10003  This is not the typical Mel Brooks film. It wa...       8   pos   \n",
       "\n",
       "   length  \n",
       "0     140  \n",
       "1     428  \n",
       "2     147  \n",
       "3     124  \n",
       "4     120  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain length of review\n",
    "train['length'] = train['text'].apply(lambda review_text: len(review_text.split(\" \")))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='length', ylabel='Density'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot review length\n",
    "sns.distplot(train['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       233.776720\n",
       "std        173.715418\n",
       "min         10.000000\n",
       "25%        127.000000\n",
       "50%        174.000000\n",
       "75%        284.000000\n",
       "max       2470.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>230.85776</td>\n",
       "      <td>166.647979</td>\n",
       "      <td>10.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>12500.0</td>\n",
       "      <td>236.69568</td>\n",
       "      <td>180.465831</td>\n",
       "      <td>12.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        length                                                          \n",
       "         count       mean         std   min    25%    50%    75%     max\n",
       "label                                                                   \n",
       "neg    12500.0  230.85776  166.647979  10.0  128.0  174.0  278.0  1522.0\n",
       "pos    12500.0  236.69568  180.465831  12.0  125.0  174.0  291.0  2470.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive reviews are slightly longer than negative reviews; \n",
    "#positive reviews also have greater variation in their length\n",
    "train[['label','length', ]].groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization and Sampling\n",
    "\n",
    "In this step, we normalize the text by carrying out standard preprocessing (lemmatization, stop word removal, punctuation removal, lower-casing, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find most common words in each of positive and negative classes, after preprocessing\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from joblib import delayed, Parallel\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def preproc(txt):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #lower case\n",
    "    txt = txt.lower()\n",
    "    #tokenize\n",
    "    word_list = word_tokenize(txt)\n",
    "    #remove punctuation\n",
    "    word_list = [word for word in word_list if word.isalnum()]\n",
    "    #remove numbers\n",
    "    word_list = [word for word in word_list if not word.isnumeric()]\n",
    "    #remove stopwords\n",
    "    word_list = [word for word in word_list if word not in stopword_list]\n",
    "    #stem the words\n",
    "    word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "train['preproc_text'] = train['text'].apply(preproc)\n",
    "test['preproc_text'] = test['text'].apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persist\n",
    "train.to_csv(\"train_proc.csv\", index=False)\n",
    "test.to_csv(\"test_proc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample with constant seed for reproducibility\n",
    "train_sample = train.sample(frac=0.1, random_state=108)\n",
    "test_sample = test.sample(frac=0.1, random_state=108)\n",
    "train_sample.to_csv(\"train_sample.csv\", index=False)\n",
    "test_sample.to_csv(\"test_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read back in\n",
    "train = pd.read_csv(\"train_proc.csv\")\n",
    "test = pd.read_csv(\"test_proc.csv\")\n",
    "\n",
    "train_sample = pd.read_csv(\"train_sample.csv\")\n",
    "test_sample = pd.read_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristic words in each sentiment class\n",
    "\n",
    "We now use count vectorization and tfidf techniques to identify characteristic words in each sentiment class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_text = \" \".join(train[train['label'] == 'pos']['preproc_text'].to_numpy())\n",
    "neg_text = \" \".join(train[train['label'] == 'neg']['preproc_text'].to_numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00s</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06th</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08th</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ne</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word       pos       neg\n",
       "0   00s  0.000014  0.000013\n",
       "1  06th  0.000019  0.000000\n",
       "2  08th  0.000019  0.000000\n",
       "3    0f  0.000000  0.000018\n",
       "4   0ne  0.000019  0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([pos_text, neg_text])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf_df = pd.DataFrame(denselist, columns=feature_names)\n",
    "tfidf_df = tfidf_df.transpose()\n",
    "tfidf_df = tfidf_df.reset_index()\n",
    "tfidf_df.columns = ['word', 'pos', 'neg']\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most characteristic words for positive reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>br</td>\n",
       "      <td>0.671724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>film</td>\n",
       "      <td>0.327751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37930</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.299974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40383</th>\n",
       "      <td>one</td>\n",
       "      <td>0.187949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>like</td>\n",
       "      <td>0.122939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57531</th>\n",
       "      <td>time</td>\n",
       "      <td>0.106595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>good</td>\n",
       "      <td>0.102188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54534</th>\n",
       "      <td>story</td>\n",
       "      <td>0.098750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>character</td>\n",
       "      <td>0.094234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24181</th>\n",
       "      <td>great</td>\n",
       "      <td>0.086553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word       pos\n",
       "7018          br  0.671724\n",
       "20710       film  0.327751\n",
       "37930      movie  0.299974\n",
       "40383        one  0.187949\n",
       "33176       like  0.122939\n",
       "57531       time  0.106595\n",
       "23772       good  0.102188\n",
       "54534      story  0.098750\n",
       "9495   character  0.094234\n",
       "24181      great  0.086553"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive and negative reviews mostly tend to share words\n",
    "print(\"Top 10 most characteristic words for positive reviews\")\n",
    "tfidf_df.sort_values('pos', ascending=False)[['word', 'pos']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most characteristic words for negative reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>br</td>\n",
       "      <td>0.681625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37930</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.363034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>film</td>\n",
       "      <td>0.278187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40383</th>\n",
       "      <td>one</td>\n",
       "      <td>0.168865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>like</td>\n",
       "      <td>0.145012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63466</th>\n",
       "      <td>would</td>\n",
       "      <td>0.099351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>even</td>\n",
       "      <td>0.099247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>good</td>\n",
       "      <td>0.093523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57531</th>\n",
       "      <td>time</td>\n",
       "      <td>0.093316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.092448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word       neg\n",
       "7018      br  0.681625\n",
       "37930  movie  0.363034\n",
       "20710   film  0.278187\n",
       "40383    one  0.168865\n",
       "33176   like  0.145012\n",
       "63466  would  0.099351\n",
       "19140   even  0.099247\n",
       "23772   good  0.093523\n",
       "57531   time  0.093316\n",
       "4230     bad  0.092448"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 most characteristic words for negative reviews\")\n",
    "tfidf_df.sort_values('neg', ascending=False)[['word', 'neg']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00s</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06th</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08th</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ne</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  pos  neg\n",
       "0   00s    1    1\n",
       "1  06th    1    0\n",
       "2  08th    1    0\n",
       "3    0f    0    1\n",
       "4   0ne    1    0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(min_df=)\n",
    "vectors = cvec.fit_transform([pos_text, neg_text],)\n",
    "feature_names = cvec.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "cvec_df = pd.DataFrame(denselist, columns=feature_names)\n",
    "cvec_df = cvec_df.transpose()\n",
    "cvec_df = cvec_df.reset_index()\n",
    "cvec_df.columns = ['word', 'pos', 'neg']\n",
    "cvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common words in positive reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>br</td>\n",
       "      <td>49235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>film</td>\n",
       "      <td>24023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37930</th>\n",
       "      <td>movie</td>\n",
       "      <td>21987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40383</th>\n",
       "      <td>one</td>\n",
       "      <td>13776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>like</td>\n",
       "      <td>9011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57531</th>\n",
       "      <td>time</td>\n",
       "      <td>7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>good</td>\n",
       "      <td>7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54534</th>\n",
       "      <td>story</td>\n",
       "      <td>7238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>character</td>\n",
       "      <td>6907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24181</th>\n",
       "      <td>great</td>\n",
       "      <td>6344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word    pos\n",
       "7018          br  49235\n",
       "20710       film  24023\n",
       "37930      movie  21987\n",
       "40383        one  13776\n",
       "33176       like   9011\n",
       "57531       time   7813\n",
       "23772       good   7490\n",
       "54534      story   7238\n",
       "9495   character   6907\n",
       "24181      great   6344"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 most common words in positive reviews\")\n",
    "cvec_df.sort_values('pos', ascending=False)[['word', 'pos']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common words in negative reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>br</td>\n",
       "      <td>52636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37930</th>\n",
       "      <td>movie</td>\n",
       "      <td>28034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>film</td>\n",
       "      <td>21482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40383</th>\n",
       "      <td>one</td>\n",
       "      <td>13040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>like</td>\n",
       "      <td>11198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63466</th>\n",
       "      <td>would</td>\n",
       "      <td>7672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>even</td>\n",
       "      <td>7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>good</td>\n",
       "      <td>7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57531</th>\n",
       "      <td>time</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>bad</td>\n",
       "      <td>7139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    neg\n",
       "7018      br  52636\n",
       "37930  movie  28034\n",
       "20710   film  21482\n",
       "40383    one  13040\n",
       "33176   like  11198\n",
       "63466  would   7672\n",
       "19140   even   7664\n",
       "23772   good   7222\n",
       "57531   time   7206\n",
       "4230     bad   7139"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 most common words in negative reviews\")\n",
    "cvec_df.sort_values('neg', ascending=False)[['word', 'neg']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the two classes tend to share the same words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "I will extract three types of features:\n",
    "- tfidf vectorization: unigrams, bigrams\n",
    "- doc2vec vectorization: 50, 100 dimensional embeddings\n",
    "- averaged Glove embeddings: 50, 100  dimensional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = pd.read_csv(\"train_sample.csv\")\n",
    "test_sample = pd.read_csv(\"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf vectorization\n",
    "\n",
    "### unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "train_corpus = train['preproc_text'].values\n",
    "test_corpus = test['preproc_text'].values\n",
    "train_corpus_sample = train_sample['preproc_text'].values\n",
    "test_corpus_sample = test_sample['preproc_text'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_1 = TfidfVectorizer(ngram_range=(1,1), min_df=2)\n",
    "tfidf_1.fit(train_corpus)\n",
    "train_x_tfidf_1 = tfidf_1.transform(train_corpus)\n",
    "test_x_tfidf_1 = tfidf_1.transform(test_corpus)\n",
    "train_x_tfidf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x13285 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 225203 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_1 = TfidfVectorizer(ngram_range=(1,1), min_df=2)\n",
    "tfidf_1.fit(train_corpus_sample)\n",
    "train_x_tfidf_1_sample = tfidf_1.transform(train_corpus_sample)\n",
    "test_x_tfidf_1_sample = tfidf_1.transform(test_corpus_sample)\n",
    "train_x_tfidf_1_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train x\n",
    "pkl.dump(train_x_tfidf_1, open('features/train_x_tfidf_1.pkl','wb'))\n",
    "pkl.dump(test_x_tfidf_1, open('features/test_x_tfidf_1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_tfidf_1_sample, open('features/train_x_tfidf_1.pkl_sample','wb'))\n",
    "pkl.dump(test_x_tfidf_1_sample, open('features/test_x_tfidf_1.pkl_sample','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x67079 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 978853 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_2 = TfidfVectorizer(ngram_range=(2,2), min_df=5)\n",
    "tfidf_2.fit(train_corpus)\n",
    "train_x_tfidf_2 = tfidf_2.transform(train_corpus)\n",
    "test_x_tfidf_2 = tfidf_2.transform(test_corpus)\n",
    "train_x_tfidf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x3641 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 37449 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_2 = TfidfVectorizer(ngram_range=(2,2), min_df=5)\n",
    "tfidf_2.fit(train_corpus_sample)\n",
    "train_x_tfidf_2_sample = tfidf_2.transform(train_corpus_sample)\n",
    "test_x_tfidf_2_sample = tfidf_2.transform(test_corpus_sample)\n",
    "train_x_tfidf_2_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_tfidf_2, open('features/train_x_tfidf_2.pkl','wb'))\n",
    "pkl.dump(test_x_tfidf_2, open('features/test_x_tfidf_2.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_tfidf_2_sample, open('features/train_x_tfidf_2.pkl_sample','wb'))\n",
    "pkl.dump(test_x_tfidf_2_sample, open('features/test_x_tfidf_2.pkl_sample','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec vectorization\n",
    "\n",
    "### 50 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_lol = [doc.split(\" \") for doc in train_corpus]\n",
    "test_corpus_lol = [doc.split(\" \") for doc in test_corpus]\n",
    "train_corpus_lol = [TaggedDocument(tup[1], [tup[0]]) for tup in enumerate(train_corpus_lol)]\n",
    "test_corpus_lol = [TaggedDocument(tup[1], [tup[0]]) for tup in enumerate(test_corpus_lol)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_lol_sample = [doc.split(\" \") for doc in train_corpus_sample]\n",
    "test_corpus_lol_sample = [doc.split(\" \") for doc in test_corpus_sample]\n",
    "train_corpus_lol_sample = [TaggedDocument(tup[1], [tup[0]]) for tup in enumerate(train_corpus_lol_sample)]\n",
    "test_corpus_lol_sample = [TaggedDocument(tup[1], [tup[0]]) for tup in enumerate(test_corpus_lol_sample)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_model_50 = Doc2Vec(vector_size=50, epochs = 40)\n",
    "doc_vec_model_50.build_vocab(train_corpus_lol)\n",
    "doc_vec_model_50.train(train_corpus_lol, total_examples=doc_vec_model_50.corpus_count, epochs = 40)\n",
    "train_x_docvec_50 = np.array([doc_vec_model_50.infer_vector(doc[0]) for doc in train_corpus_lol])\n",
    "test_x_docvec_50 = np.array([doc_vec_model_50.infer_vector(doc[0]) for doc in test_corpus_lol])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_model_50 = Doc2Vec(vector_size=50, epochs = 40)\n",
    "doc_vec_model_50.build_vocab(train_corpus_lol_sample)\n",
    "doc_vec_model_50.train(train_corpus_lol_sample, total_examples=doc_vec_model_50.corpus_count, epochs = 40)\n",
    "train_x_docvec_50_sample = np.array([doc_vec_model_50.infer_vector(doc[0]) for doc in train_corpus_lol_sample])\n",
    "test_x_docvec_50_sample = np.array([doc_vec_model_50.infer_vector(doc[0]) for doc in test_corpus_lol_sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_docvec_50, open(\"features/train_x_docvec_50.pkl\",'wb'))\n",
    "pkl.dump(test_x_docvec_50, open(\"features/test_x_docvec_50.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_docvec_50_sample, open(\"features/train_x_docvec_50_sample.pkl\",'wb'))\n",
    "pkl.dump(test_x_docvec_50_sample, open(\"features/test_x_docvec_50_sample.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_model_100 = Doc2Vec(vector_size=100, epochs = 40)\n",
    "doc_vec_model_100.build_vocab(train_corpus_lol)\n",
    "doc_vec_model_100.train(train_corpus_lol, total_examples=doc_vec_model_100.corpus_count, epochs = 40)\n",
    "train_x_docvec_100 = np.array([doc_vec_model_100.infer_vector(doc[0]) for doc in train_corpus_lol])\n",
    "test_x_docvec_100 = np.array([doc_vec_model_100.infer_vector(doc[0]) for doc in test_corpus_lol])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_model_100 = Doc2Vec(vector_size=100, epochs = 40)\n",
    "doc_vec_model_100.build_vocab(train_corpus_lol_sample)\n",
    "doc_vec_model_100.train(train_corpus_lol_sample, total_examples=doc_vec_model_100.corpus_count, epochs = 40)\n",
    "train_x_docvec_100_sample = np.array([doc_vec_model_100.infer_vector(doc[0]) for doc in train_corpus_lol_sample])\n",
    "test_x_docvec_100_sample = np.array([doc_vec_model_100.infer_vector(doc[0]) for doc in test_corpus_lol_sample])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_docvec_100, open(\"features/train_x_docvec_100.pkl\",'wb'))\n",
    "pkl.dump(test_x_docvec_100, open(\"features/test_x_docvec_100.pkl\",'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_docvec_100_sample, open(\"features/train_x_docvec_100_sample.pkl\",'wb'))\n",
    "pkl.dump(test_x_docvec_100_sample, open(\"features/test_x_docvec_100_sample.pkl\",'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLoVE Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api \n",
    "info = api.info()\n",
    "info['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wiki_model_50 = api.load('glove-wiki-gigaword-50')\n",
    "glove_wiki_model_100 = api.load('glove-wiki-gigaword-100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_doc_vec(doc, model):\n",
    "    \"\"\"Takes a doc in string format and uses model to generate an averaged vector of its word vectors\"\"\"\n",
    "    tokens = doc.split(\" \")\n",
    "    tokens = [token for token in tokens if token in model.vocab.keys()]\n",
    "    word_vecs = []\n",
    "    for token in tokens:\n",
    "        word_vec = model.get_vector(token)\n",
    "        word_vecs.append(word_vec)\n",
    "    return np.mean(word_vecs, axis = 0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_glove_50 = np.array([word_to_doc_vec(doc, glove_wiki_model_50) for doc in train_corpus])\n",
    "test_x_glove_50 = np.array([word_to_doc_vec(doc, glove_wiki_model_50) for doc in test_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_glove_50_sample = np.array([word_to_doc_vec(doc, glove_wiki_model_50) for doc in train_corpus_sample])\n",
    "test_x_glove_50_sample = np.array([word_to_doc_vec(doc, glove_wiki_model_50) for doc in test_corpus_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_glove_50, open('features/train_x_glove_50.pkl', 'wb'))\n",
    "pkl.dump(test_x_glove_50, open('features/test_x_glove_50.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_glove_50_sample, open('features/train_x_glove_50_sample.pkl', 'wb'))\n",
    "pkl.dump(test_x_glove_50_sample, open('features/test_x_glove_50_sample.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_glove_100 = np.array([word_to_doc_vec(doc, glove_wiki_model_100) for doc in train_corpus])\n",
    "test_x_glove_100 = np.array([word_to_doc_vec(doc, glove_wiki_model_100) for doc in test_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_glove_100_sample = np.array([word_to_doc_vec(doc, glove_wiki_model_100) for doc in train_corpus_sample])\n",
    "test_x_glove_100_sample = np.array([word_to_doc_vec(doc, glove_wiki_model_100) for doc in test_corpus_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_glove_100, open('features/train_x_glove_100.pkl', 'wb'))\n",
    "pkl.dump(test_x_glove_100, open('features/test_x_glove_100.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(train_x_glove_100_sample, open('features/train_x_glove_100_sample.pkl', 'wb'))\n",
    "pkl.dump(test_x_glove_100_sample, open('features/test_x_glove_100_sample.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "\n",
    "<p style=\"font-size:20px\"><b> Load features </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf_1 = pkl.load(open('features/train_x_tfidf_1.pkl','rb'))\n",
    "test_x_tfidf_1 = pkl.load(open('features/test_x_tfidf_1.pkl','rb'))\n",
    "\n",
    "train_x_tfidf_2 = pkl.load(open('features/train_x_tfidf_2.pkl','rb'))\n",
    "test_x_tfidf_2 = pkl.load(open('features/test_x_tfidf_2.pkl','rb'))\n",
    "\n",
    "train_x_docvec_50 = pkl.load(open(\"features/train_x_docvec_50.pkl\",'rb'))\n",
    "test_x_docvec_50 = pkl.load(open(\"features/test_x_docvec_50.pkl\",'rb'))\n",
    "\n",
    "train_x_docvec_100 = pkl.load(open(\"features/train_x_docvec_100.pkl\",'rb'))\n",
    "test_x_docvec_100 = pkl.load(open(\"features/test_x_docvec_100.pkl\",'rb'))\n",
    "\n",
    "train_x_glove_50 = pkl.load(open('features/train_x_glove_50.pkl', 'rb'))\n",
    "test_x_glove_50 = pkl.load(open('features/test_x_glove_50.pkl', 'rb'))\n",
    "\n",
    "train_x_glove_100 = pkl.load(open('features/train_x_glove_100.pkl', 'rb'))\n",
    "test_x_glove_100 = pkl.load(open('features/test_x_glove_100.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tfidf_1_sample = pkl.load(open('features/train_x_tfidf_1_sample.pkl','rb'))\n",
    "test_x_tfidf_1_sample = pkl.load(open('features/test_x_tfidf_1_sample.pkl','rb'))\n",
    "\n",
    "train_x_tfidf_2_sample = pkl.load(open('features/train_x_tfidf_2_sample.pkl','rb'))\n",
    "test_x_tfidf_2_sample = pkl.load(open('features/test_x_tfidf_2_sample.pkl','rb'))\n",
    "\n",
    "train_x_docvec_50_sample = pkl.load(open(\"features/train_x_docvec_50_sample.pkl\",'rb'))\n",
    "test_x_docvec_50_sample = pkl.load(open(\"features/test_x_docvec_50_sample.pkl\",'rb'))\n",
    "\n",
    "train_x_docvec_100_sample = pkl.load(open(\"features/train_x_docvec_100_sample.pkl\",'rb'))\n",
    "test_x_docvec_100_sample = pkl.load(open(\"features/test_x_docvec_100_sample.pkl\",'rb'))\n",
    "\n",
    "train_x_glove_50_sample = pkl.load(open('features/train_x_glove_50_sample.pkl', 'rb'))\n",
    "test_x_glove_50_sample = pkl.load(open('features/test_x_glove_50_sample.pkl', 'rb'))\n",
    "\n",
    "train_x_glove_100_sample = pkl.load(open('features/train_x_glove_100_sample.pkl', 'rb'))\n",
    "test_x_glove_100_sample = pkl.load(open('features/test_x_glove_100_sample.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['label'].to_numpy()\n",
    "train_y = [1 if label=='pos' else 0 for label in train_y]\n",
    "test_y = test['label'].to_numpy()\n",
    "test_y = [1 if label=='pos' else 0 for label in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sample = train_sample['label'].to_numpy()\n",
    "train_y_sample = [1 if label=='pos' else 0 for label in train_y_sample]\n",
    "test_y_sample = test_sample['label'].to_numpy()\n",
    "test_y_sample = [1 if label=='pos' else 0 for label in test_y_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important notes: \n",
    "\n",
    "- The general approach is to tune the hyperparamters using a 5 fold cross validation approach.\n",
    "- To speed up the hyperparameter tuning process, I used a RandomGrid Search approach, where combinations of parameters are randomly sampled from the parameter space, and the model is evaluated on them. In practice, this usually gives good results.\n",
    "- The metrics that the model will be judged on is **F1 score**. Accuracy will also be computed to bring more context.\n",
    "- During model development, it will sometimes be necessary to use a sampled version of the dataset to reduce training times. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "def tune_hyperparams(model, params_dict, train_x, train_y, random=True):\n",
    "    \"\"\"Tunes hyperparams for MODEL by exploring parameter space defined by PARAMS_DICT \n",
    "    using data provided by TRAIN_X, TRAIN_Y\"\"\"\n",
    "    if random:\n",
    "        cv = RandomizedSearchCV(estimator=model, param_distributions=params_dict,\n",
    "                               n_iter=10, scoring='f1', n_jobs=-1,\n",
    "                               cv=5, refit=True, random_state=108)\n",
    "    else:\n",
    "        cv = GridSearchCV(estimator=model, param_grid=params_dict, \n",
    "                          scoring='f1',n_jobs=-1, cv = 5,\n",
    "                         refit = True)\n",
    "    cv.fit(train_x, train_y)\n",
    "    best_params = cv.best_params_\n",
    "    best_score = cv.best_score_\n",
    "    best_model = cv.best_estimator_\n",
    "    results = {\n",
    "        'model_name': model, \n",
    "        'best_params': best_params,\n",
    "        'best_score': best_score,\n",
    "        'best_model': best_model\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def evaluate_model(model, params_dict, train_x, train_y, test_x, test_y):\n",
    "    \"\"\"Evaluates MODEL generalization performance over provided test set\"\"\"\n",
    "    hyperparam_tuning_results = tune_hyperparams(model, params_dict, \n",
    "                                                 train_x, train_y)\n",
    "    best_model = hyperparam_tuning_results['best_model']\n",
    "    pred = best_model.predict(test_x)\n",
    "    test_f1 = f1_score(test_y, pred)\n",
    "    test_accuracy = accuracy_score(test_y, pred)\n",
    "    results = {\n",
    "        'model_name': model,\n",
    "        'best_params': hyperparam_tuning_results['best_params'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1_score': test_f1\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_model = LogisticRegression(solver = 'liblinear')\n",
    "log_reg_pd = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 1, 'penalty': 'l1'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.87468,\n",
      " 'test_f1_score': 0.8761709023358759}\n"
     ]
    }
   ],
   "source": [
    "log_reg_tfidf_1_results = evaluate_model(log_reg_model, log_reg_pd, train_x_tfidf_1, train_y, test_x_tfidf_1, test_y)\n",
    "pprint(log_reg_tfidf_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 1, 'penalty': 'l2'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.83948,\n",
      " 'test_f1_score': 0.840125891398749}\n"
     ]
    }
   ],
   "source": [
    "log_reg_tfidf_2_results = evaluate_model(log_reg_model, log_reg_pd, train_x_tfidf_2, train_y, test_x_tfidf_2, test_y)\n",
    "pprint(log_reg_tfidf_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 1, 'penalty': 'l2'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.81636,\n",
      " 'test_f1_score': 0.8076906966028568}\n"
     ]
    }
   ],
   "source": [
    "log_reg_docvec_50_results = evaluate_model(log_reg_model, log_reg_pd, train_x_docvec_50, train_y, test_x_docvec_50, test_y)\n",
    "pprint(log_reg_docvec_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 0.01, 'penalty': 'l2'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.82576,\n",
      " 'test_f1_score': 0.8237008256435162}\n"
     ]
    }
   ],
   "source": [
    "log_reg_docvec_100_results = evaluate_model(log_reg_model, log_reg_pd, train_x_docvec_100, train_y, test_x_docvec_100, test_y)\n",
    "pprint(log_reg_docvec_100_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 10, 'penalty': 'l2'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.7356,\n",
      " 'test_f1_score': 0.7365484256675966}\n"
     ]
    }
   ],
   "source": [
    "log_reg_glove_50_results = evaluate_model(log_reg_model, log_reg_pd, train_x_glove_50_sample, train_y_sample, \n",
    "                                          test_x_glove_50_sample, test_y_sample)\n",
    "pprint(log_reg_glove_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 5, 'penalty': 'l1'},\n",
      " 'model_name': LogisticRegression(solver='liblinear'),\n",
      " 'test_accuracy': 0.79524,\n",
      " 'test_f1_score': 0.7944754486690488}\n"
     ]
    }
   ],
   "source": [
    "log_reg_glove_100_results = evaluate_model(log_reg_model, log_reg_pd, train_x_glove_100, train_y, test_x_glove_100, test_y)\n",
    "pprint(log_reg_glove_100_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler(with_mean=False)\n",
    "svc = LinearSVC(random_state=108, max_iter=10000)\n",
    "svc_pd = {\n",
    "    'C': np.arange(0.1,20,0.1),\n",
    "    'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 8.4, 'loss': 'epsilon_insensitive'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.62048,\n",
      " 'test_f1_score': 0.7169113259338823}\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf_1_results = evaluate_model(svc, svc_pd, ss.fit_transform(train_x_tfidf_1), train_y, \n",
    "                                    ss.fit_transform(test_x_tfidf_1), test_y)\n",
    "pprint(svc_tfidf_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 8.4, 'loss': 'epsilon_insensitive'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.57336,\n",
      " 'test_f1_score': 0.699633905941988}\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf_2_results = evaluate_model(svc, svc_pd, ss.fit_transform(train_x_tfidf_2), train_y, \n",
    "                                    ss.fit_transform(test_x_tfidf_2), test_y)\n",
    "pprint(svc_tfidf_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 8.4, 'loss': 'epsilon_insensitive'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.5728,\n",
      " 'test_f1_score': 0.7043189368770764}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc_docvec_50_results = evaluate_model(svc, svc_pd, train_x_docvec_50_sample, train_y_sample, \n",
    "                                       test_x_docvec_50_sample, test_y_sample)\n",
    "pprint(svc_docvec_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 8.4, 'loss': 'epsilon_insensitive'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.5952,\n",
      " 'test_f1_score': 0.7154105736782902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc_docvec_100_results = evaluate_model(svc, svc_pd, train_x_docvec_100_sample, train_y_sample, \n",
    "                                        test_x_docvec_100_sample, test_y_sample)\n",
    "pprint(svc_docvec_100_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 1, 'penalty': 'l2'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.75244,\n",
      " 'test_f1_score': 0.7496460499170746}\n"
     ]
    }
   ],
   "source": [
    "svc_glove_50_results = evaluate_model(svc, svc_pd, train_x_glove_50, train_y, test_x_glove_50, test_y)\n",
    "pprint(svc_glove_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'C': 8.4, 'loss': 'epsilon_insensitive'},\n",
      " 'model_name': LinearSVC(max_iter=10000, random_state=108),\n",
      " 'test_accuracy': 0.586,\n",
      " 'test_f1_score': 0.7093513058129739}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc_glove_100_results = evaluate_model(svc, svc_pd, train_x_glove_100_sample, train_y_sample, \n",
    "                                       test_x_glove_100_sample, test_y_sample)\n",
    "pprint(svc_glove_100_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_pd = {\n",
    "    'n_neighbors': np.arange(3,200,1),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': np.arange(1,10, 1),\n",
    "    'metric': ['minkowski', 'chebyshev']\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 11,\n",
      "                 'p': 1,\n",
      "                 'weights': 'distance'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.5148,\n",
      " 'test_f1_score': 0.6790156125959248}\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf_1_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_tfidf_1_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_tfidf_1_sample), test_y_sample)\n",
    "pprint(knn_tfidf_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 11,\n",
      "                 'p': 1,\n",
      "                 'weights': 'distance'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.5132,\n",
      " 'test_f1_score': 0.6782976473698124}\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf_2_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_tfidf_2_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_tfidf_2_sample), test_y_sample)\n",
    "pprint(knn_tfidf_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 142,\n",
      "                 'p': 3,\n",
      "                 'weights': 'distance'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.7692,\n",
      " 'test_f1_score': 0.7899526756461593}\n"
     ]
    }
   ],
   "source": [
    "knn_docvec_50_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_docvec_50_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_docvec_50_sample), test_y_sample)\n",
    "pprint(knn_docvec_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 36,\n",
      "                 'p': 1,\n",
      "                 'weights': 'uniform'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.7208,\n",
      " 'test_f1_score': 0.7554309740714786}\n"
     ]
    }
   ],
   "source": [
    "knn_docvec_100_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_docvec_100_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_docvec_100_sample), test_y_sample)\n",
    "pprint(knn_docvec_100_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 36,\n",
      "                 'p': 1,\n",
      "                 'weights': 'uniform'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.7056,\n",
      " 'test_f1_score': 0.6830318690783806}\n"
     ]
    }
   ],
   "source": [
    "knn_glove_50_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_glove_50_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_glove_50_sample), test_y_sample)\n",
    "pprint(knn_glove_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'metric': 'minkowski',\n",
      "                 'n_neighbors': 11,\n",
      "                 'p': 1,\n",
      "                 'weights': 'distance'},\n",
      " 'model_name': KNeighborsClassifier(),\n",
      " 'test_accuracy': 0.7072,\n",
      " 'test_f1_score': 0.701468189233279}\n"
     ]
    }
   ],
   "source": [
    "knn_glove_100_results = evaluate_model(knn, knn_pd, ss.fit_transform(train_x_glove_100_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_glove_100_sample), test_y_sample)\n",
    "pprint(knn_glove_100_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=108)\n",
    "\n",
    "rf_pd = {\n",
    "    'n_estimators': np.arange(10,400,10),\n",
    "    'max_features': np.concatenate((np.arange(0.1, 1.0, 0.1), np.array(['auto', 'sqrt', 'log2'])))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'sqrt', 'n_estimators': 390},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.8232,\n",
      " 'test_f1_score': 0.8280155642023347}\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf_1_results = evaluate_model(rf, rf_pd, train_x_tfidf_1_sample, train_y_sample, \n",
    "                                    test_x_tfidf_1_sample, test_y_sample)\n",
    "pprint(rf_tfidf_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'auto', 'n_estimators': 220},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.7172,\n",
      " 'test_f1_score': 0.7370769802900707}\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf_2_results = evaluate_model(rf, rf_pd, train_x_tfidf_2_sample, train_y_sample, \n",
    "                                    test_x_tfidf_2_sample, test_y_sample)\n",
    "pprint(rf_tfidf_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'sqrt', 'n_estimators': 390},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.786,\n",
      " 'test_f1_score': 0.788621098380087}\n"
     ]
    }
   ],
   "source": [
    "rf_docvec_50_results = evaluate_model(rf, rf_pd, ss.fit_transform(train_x_docvec_50_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_docvec_50_sample), test_y_sample)\n",
    "pprint(rf_docvec_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'sqrt', 'n_estimators': 390},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.7708,\n",
      " 'test_f1_score': 0.7741426882144264}\n"
     ]
    }
   ],
   "source": [
    "rf_docvec_100_results = evaluate_model(rf, rf_pd, ss.fit_transform(train_x_docvec_100_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_docvec_100_sample), test_y_sample)\n",
    "pprint(rf_docvec_100_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'auto', 'n_estimators': 220},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.7252,\n",
      " 'test_f1_score': 0.7287801026450849}\n"
     ]
    }
   ],
   "source": [
    "rf_glove_50_results = evaluate_model(rf, rf_pd, ss.fit_transform(train_x_glove_50_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_glove_50_sample), test_y_sample)\n",
    "pprint(rf_glove_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'max_features': 'sqrt', 'n_estimators': 390},\n",
      " 'model_name': RandomForestClassifier(random_state=108),\n",
      " 'test_accuracy': 0.7504,\n",
      " 'test_f1_score': 0.7579519006982156}\n"
     ]
    }
   ],
   "source": [
    "rf_glove_100_results = evaluate_model(rf, rf_pd, ss.fit_transform(train_x_glove_100_sample), train_y_sample, \n",
    "                                    ss.fit_transform(test_x_glove_100_sample), test_y_sample)\n",
    "pprint(rf_glove_100_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "\n",
    "**The GBC model takes quite a long time to run, and so I wasn't able to obtain results for it, even after sampling.** The code is included her for reference, but it is recommended not to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=108)\n",
    "gbc_pd = {\n",
    "    'n_estimators': np.arange(10, 20, 1), #number of boosting iterations\n",
    "    'max_depth': np.arange(1, 50, 1), #interaction depth\n",
    "    'learning_rate':np.arange(0.1,1,0.01), #learning rate for weak learner update\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_params': {'learning_rate': 0.23999999999999994,\n",
      "                 'max_depth': 14,\n",
      "                 'n_estimators': 10},\n",
      " 'model_name': GradientBoostingClassifier(random_state=108),\n",
      " 'test_accuracy': 0.738,\n",
      " 'test_f1_score': 0.753666792027078}\n"
     ]
    }
   ],
   "source": [
    "gbc_tfidf_1_results = evaluate_model(gbc, gbc_pd, train_x_tfidf_1_sample, train_y_sample, \n",
    "                                    test_x_tfidf_1_sample, test_y_sample)\n",
    "pprint(gbc_tfidf_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_tfidf_2_results = evaluate_model(gbc, gbc_pd, train_x_tfidf_2_sample, train_y_sample, \n",
    "                                    test_x_tfidf_2_sample, test_y_sample)\n",
    "pprint(gbc_tfidf_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_docvec_50_results = evaluate_model(gbc, gbc_pd, train_x_docvec_50_sample, train_y_sample, \n",
    "                                    test_x_docvec_50_sample, test_y_sample)\n",
    "pprint(gbc_docvec_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_docvec_100_results = evaluate_model(gbc, gbc_pd, train_x_docvec_100_sample, train_y_sample, \n",
    "                                    test_x_docvec_100_sample, test_y_sample)\n",
    "pprint(gbc_docvec_100_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_glove_50_results = evaluate_model(gbc, gbc_pd, train_x_glove_50_sample, train_y_sample, \n",
    "                                    test_x_glove_50_sample, test_y_sample)\n",
    "pprint(gbc_glove_50_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_glove_100_results = evaluate_model(gbc, gbc_pd, train_x_glove_100_sample, train_y_sample, \n",
    "                                    test_x_glove_100_sample, test_y_sample)\n",
    "pprint(gbc_glove_100_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\"><b> Final Results </b></p>\n",
    "\n",
    "\n",
    "Now, that we have completed model development. Let's summarize best performance results:\n",
    "- **Logistic Regression**:  test_accuracy: 0.875, test_f1: 0.876 || C=1, penalty='l1' || tfidf_1 \n",
    "- **SVM Classifier**: performance: test_accuracy: 0.752, test_f1: 0.7496 || C=1, penalty='l2' || glove_50 \n",
    "- **k-Nearest Neighbor Classifier**: test_accuracy: 0.7692, test_f1: 0.7899 || metric='minkowski', n_neighbors: 142, p=3, weights='distance' || docvec_50\n",
    "- **Random Forest Classifier**: test_accuracy: 0.8232, test_f1: 0.8280 || max_features='sqrt', n_estimators: 390 ||  tfidf_1\n",
    "\n",
    "\n",
    "As a final conclusion of the model development, it looks like the **logistic regression with tfidf unigram features** performs better than the rest, with a 87.5% test set accuracy, and a 87.6% test set F1 score.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation\n",
    "\n",
    "One major advantage of the logistic regression approach with tfidf features is its high level of interpretability. It is also beneficial that the logistic regression approach is highly performant in this use case as proven above. \n",
    "\n",
    "\n",
    "\n",
    "## Plotting ROC curve and identifying optimal decision probability cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance\n",
      "Accuracy: 0.89668\n",
      "F1 Score: 0.8980220300840933\n",
      "-----------------\n",
      "Testing set performance\n",
      "Accuracy: 0.87468\n",
      "F1 Score: 0.8761709023358759\n",
      "Optimal threshold: 0.4979108320487417\n",
      "Optimal TPR: 0.88808\n",
      "Optimal FPR: 0.1384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1d8d4b51280>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, plot_roc_curve, roc_curve\n",
    "log_reg_model = LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
    "log_reg_model.fit(train_x_tfidf_1, train_y)\n",
    "train_pred = log_reg_model.predict(train_x_tfidf_1)\n",
    "test_pred = log_reg_model.predict(test_x_tfidf_1)\n",
    "\n",
    "print(\"Training set performance\")\n",
    "print(f\"Accuracy: {accuracy_score(train_y,train_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(train_y,train_pred)}\")\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(\"Testing set performance\")\n",
    "print(f\"Accuracy: {accuracy_score(test_y,test_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(test_y,test_pred)}\")\n",
    "\n",
    "test_pred_pos_prob = [lst[1] for lst in log_reg_model.predict_proba(test_x_tfidf_1)]\n",
    "fpr, tpr, thresholds = roc_curve(y_score=test_pred_pos_prob,y_true=test_y, pos_label=1)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal threshold: {optimal_threshold}\")\n",
    "print(f\"Optimal TPR: {tpr[optimal_idx]}\")\n",
    "print(f\"Optimal FPR: {fpr[optimal_idx]}\")\n",
    "plot_roc_curve(log_reg_model, test_x_tfidf_1, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Coefficients\n",
    "\n",
    "Overall, the model makes sense. It associates positive sounding words with positive sentiment classifications, and negative sounding words for negative sentiment classifications.\n",
    "\n",
    "The L1 regularizations conveniently eliminates a lot of words that have no directionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00s</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100min</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100th</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38247</th>\n",
       "      <td>zy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38248</th>\n",
       "      <td>zz</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38249</th>\n",
       "      <td>élan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38250</th>\n",
       "      <td>émigré</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38251</th>\n",
       "      <td>über</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_name  coef\n",
       "0          00s   0.0\n",
       "1           10   0.0\n",
       "2         1000   0.0\n",
       "3       100min   0.0\n",
       "4        100th   0.0\n",
       "...        ...   ...\n",
       "38247       zy   0.0\n",
       "38248       zz   0.0\n",
       "38249     élan   0.0\n",
       "38250   émigré   0.0\n",
       "38251     über   0.0\n",
       "\n",
       "[38252 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_corpus = train['preproc_text'].values\n",
    "tfidf_1 = TfidfVectorizer(ngram_range=(1,1), min_df=2)\n",
    "tfidf_1.fit(train_corpus)\n",
    "log_reg_coefs = list(zip(tfidf_1.get_feature_names(), log_reg_model.coef_[0]))\n",
    "log_reg_coefs_pd = pd.DataFrame({'var_name': [tup[0] for tup in log_reg_coefs], 'coef': [tup[1] for tup in log_reg_coefs]})\n",
    "log_reg_coefs_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37745</th>\n",
       "      <td>worst</td>\n",
       "      <td>-20.824077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37010</th>\n",
       "      <td>waste</td>\n",
       "      <td>-16.947519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>awful</td>\n",
       "      <td>-15.187549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25821</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-12.352630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>-11.069421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10214</th>\n",
       "      <td>dull</td>\n",
       "      <td>-10.722295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>boring</td>\n",
       "      <td>-10.636810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>fails</td>\n",
       "      <td>-10.564024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9263</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>-10.481223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-10.011327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37733</th>\n",
       "      <td>worse</td>\n",
       "      <td>-9.934560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16053</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-9.910482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>bad</td>\n",
       "      <td>-9.852360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35665</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-9.479553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35675</th>\n",
       "      <td>unfunny</td>\n",
       "      <td>-9.434617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25818</th>\n",
       "      <td>poor</td>\n",
       "      <td>-9.312189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-9.308801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-9.195499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>annoying</td>\n",
       "      <td>-9.183707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21588</th>\n",
       "      <td>mess</td>\n",
       "      <td>-8.951833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             var_name       coef\n",
       "37745           worst -20.824077\n",
       "37010           waste -16.947519\n",
       "2296            awful -15.187549\n",
       "25821          poorly -12.352630\n",
       "9265   disappointment -11.069421\n",
       "10214            dull -10.722295\n",
       "3930           boring -10.636810\n",
       "11946           fails -10.564024\n",
       "9263    disappointing -10.481223\n",
       "25699       pointless -10.011327\n",
       "37733           worse  -9.934560\n",
       "16053        horrible  -9.910482\n",
       "2410              bad  -9.852360\n",
       "35665   unfortunately  -9.479553\n",
       "35675         unfunny  -9.434617\n",
       "25818            poor  -9.312189\n",
       "2258            avoid  -9.308801\n",
       "33911        terrible  -9.195499\n",
       "1377         annoying  -9.183707\n",
       "21588            mess  -8.951833"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#factors that predict a negative sentiment\n",
    "log_reg_coefs_pd.sort_values('coef', ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11573</th>\n",
       "      <td>excellent</td>\n",
       "      <td>12.597217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25005</th>\n",
       "      <td>perfect</td>\n",
       "      <td>9.944312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37644</th>\n",
       "      <td>wonderfully</td>\n",
       "      <td>9.877279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14487</th>\n",
       "      <td>great</td>\n",
       "      <td>9.638790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27710</th>\n",
       "      <td>refreshing</td>\n",
       "      <td>9.186866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>amazing</td>\n",
       "      <td>8.960536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>favorite</td>\n",
       "      <td>8.694486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37642</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>8.557940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15692</th>\n",
       "      <td>highly</td>\n",
       "      <td>8.543534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>best</td>\n",
       "      <td>8.008538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33015</th>\n",
       "      <td>superb</td>\n",
       "      <td>7.071029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27254</th>\n",
       "      <td>rare</td>\n",
       "      <td>7.058117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34407</th>\n",
       "      <td>today</td>\n",
       "      <td>6.776342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>6.435078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20152</th>\n",
       "      <td>loved</td>\n",
       "      <td>6.387041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>6.386856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11047</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>6.251394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32841</th>\n",
       "      <td>subtle</td>\n",
       "      <td>6.163913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13428</th>\n",
       "      <td>funniest</td>\n",
       "      <td>5.928742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12050</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>5.776807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_name       coef\n",
       "11573    excellent  12.597217\n",
       "25005      perfect   9.944312\n",
       "37644  wonderfully   9.877279\n",
       "14487        great   9.638790\n",
       "27710   refreshing   9.186866\n",
       "1090       amazing   8.960536\n",
       "12175     favorite   8.694486\n",
       "37642    wonderful   8.557940\n",
       "15692       highly   8.543534\n",
       "3186          best   8.008538\n",
       "33015       superb   7.071029\n",
       "27254         rare   7.058117\n",
       "34407        today   6.776342\n",
       "4260     brilliant   6.435078\n",
       "20152        loved   6.387041\n",
       "25011    perfectly   6.386856\n",
       "11047    enjoyable   6.251394\n",
       "32841       subtle   6.163913\n",
       "13428     funniest   5.928742\n",
       "12050    fantastic   5.776807"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#factors that predict a positive sentiment\n",
    "log_reg_coefs_pd.sort_values('coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>preproc_text</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "      <td>bromwell high cartoon comedy ran time program ...</td>\n",
       "      <td>0.573240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "      <td>0.622133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>brilliant lesley ann warren best dramatic hobo...</td>\n",
       "      <td>0.977462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "      <td>easily underrated film inn brook cannon sure f...</td>\n",
       "      <td>0.749641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>typical mel brook film much le slapstick movie...</td>\n",
       "      <td>0.908721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>9998</td>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>towards end movie felt technical felt like cla...</td>\n",
       "      <td>0.339544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9999</td>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>kind movie enemy content watch time bloody tru...</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>999</td>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>saw last night stockholm film festival one hug...</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>99</td>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>film pick pound turn rather good 23rd century ...</td>\n",
       "      <td>0.011951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>9</td>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>one dumbest film ever seen rip nearly ever typ...</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  rating label  \\\n",
       "0          0  Bromwell High is a cartoon comedy. It ran at t...       9   pos   \n",
       "1      10000  Homelessness (or Houselessness as George Carli...       8   pos   \n",
       "2      10001  Brilliant over-acting by Lesley Ann Warren. Be...      10   pos   \n",
       "3      10002  This is easily the most underrated film inn th...       7   pos   \n",
       "4      10003  This is not the typical Mel Brooks film. It wa...       8   pos   \n",
       "...      ...                                                ...     ...   ...   \n",
       "24995   9998  Towards the end of the movie, I felt it was to...       4   neg   \n",
       "24996   9999  This is the kind of movie that my enemies cont...       3   neg   \n",
       "24997    999  I saw 'Descent' last night at the Stockholm Fi...       3   neg   \n",
       "24998     99  Some films that you pick up for a pound turn o...       1   neg   \n",
       "24999      9  This is one of the dumbest films, I've ever se...       1   neg   \n",
       "\n",
       "                                            preproc_text  pred_proba  \\\n",
       "0      bromwell high cartoon comedy ran time program ...    0.573240   \n",
       "1      homelessness houselessness george carlin state...    0.622133   \n",
       "2      brilliant lesley ann warren best dramatic hobo...    0.977462   \n",
       "3      easily underrated film inn brook cannon sure f...    0.749641   \n",
       "4      typical mel brook film much le slapstick movie...    0.908721   \n",
       "...                                                  ...         ...   \n",
       "24995  towards end movie felt technical felt like cla...    0.339544   \n",
       "24996  kind movie enemy content watch time bloody tru...    0.075124   \n",
       "24997  saw last night stockholm film festival one hug...    0.005916   \n",
       "24998  film pick pound turn rather good 23rd century ...    0.011951   \n",
       "24999  one dumbest film ever seen rip nearly ever typ...    0.000436   \n",
       "\n",
       "       pred_label  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "24995           0  \n",
       "24996           0  \n",
       "24997           0  \n",
       "24998           0  \n",
       "24999           0  \n",
       "\n",
       "[25000 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_results = train.copy()\n",
    "OPTIMAL_CUTOFF_PROB = 0.49791\n",
    "log_reg_results['pred_proba'] = [lst[1] for lst in log_reg_model.predict_proba(train_x_tfidf_1)]\n",
    "\n",
    "log_reg_results['pred_label'] = (log_reg_results['pred_proba'] > OPTIMAL_CUTOFF_PROB).astype(int)\n",
    "log_reg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>preproc_text</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9895</td>\n",
       "      <td>A bunch of popular high school students play a...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>bunch popular high school student play cruel j...</td>\n",
       "      <td>0.641911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298</td>\n",
       "      <td>Sogo Ishii can be a skilled filmmaker under th...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>sogo ishii skilled filmmaker right condition g...</td>\n",
       "      <td>0.538692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>942</td>\n",
       "      <td>Saw this late one night on cable. At the time ...</td>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>saw late one night cable time know girl billed...</td>\n",
       "      <td>0.210082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9672</td>\n",
       "      <td>While most of the movie is very amateurish, th...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>movie amateurish kosher slaughter scene played...</td>\n",
       "      <td>0.582733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11804</td>\n",
       "      <td>Rented the movie as a joke. My friends and I h...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>rented movie joke friend much fun laughing wen...</td>\n",
       "      <td>0.768801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2209</td>\n",
       "      <td>In my opinion, this is a pretty good celebrity...</td>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "      <td>opinion pretty good celebrity skit show enjoye...</td>\n",
       "      <td>0.756161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>10784</td>\n",
       "      <td>It was disgusting and painful. What a waste of...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>disgusting painful waste cast swear audience f...</td>\n",
       "      <td>0.173736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>1526</td>\n",
       "      <td>I may have seen worse films than this, but I i...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>may seen worse film remember possibly blocked ...</td>\n",
       "      <td>0.338006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>7283</td>\n",
       "      <td>Facts about National Lampoon Goes to the Movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>fact national lampoon go movie national lampoo...</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>10891</td>\n",
       "      <td>You can survive Surviving Christmas. I thought...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "      <td>survive surviving christmas thought television...</td>\n",
       "      <td>0.747156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  rating label  \\\n",
       "0      9895  A bunch of popular high school students play a...       8   pos   \n",
       "1      1298  Sogo Ishii can be a skilled filmmaker under th...       3   neg   \n",
       "2       942  Saw this late one night on cable. At the time ...       2   neg   \n",
       "3      9672  While most of the movie is very amateurish, th...       3   neg   \n",
       "4     11804  Rented the movie as a joke. My friends and I h...      10   pos   \n",
       "...     ...                                                ...     ...   ...   \n",
       "2495   2209  In my opinion, this is a pretty good celebrity...       8   pos   \n",
       "2496  10784  It was disgusting and painful. What a waste of...       1   neg   \n",
       "2497   1526  I may have seen worse films than this, but I i...       1   neg   \n",
       "2498   7283  Facts about National Lampoon Goes to the Movie...       1   neg   \n",
       "2499  10891  You can survive Surviving Christmas. I thought...       7   pos   \n",
       "\n",
       "                                           preproc_text  pred_proba  \\\n",
       "0     bunch popular high school student play cruel j...    0.641911   \n",
       "1     sogo ishii skilled filmmaker right condition g...    0.538692   \n",
       "2     saw late one night cable time know girl billed...    0.210082   \n",
       "3     movie amateurish kosher slaughter scene played...    0.582733   \n",
       "4     rented movie joke friend much fun laughing wen...    0.768801   \n",
       "...                                                 ...         ...   \n",
       "2495  opinion pretty good celebrity skit show enjoye...    0.756161   \n",
       "2496  disgusting painful waste cast swear audience f...    0.173736   \n",
       "2497  may seen worse film remember possibly blocked ...    0.338006   \n",
       "2498  fact national lampoon go movie national lampoo...    0.085725   \n",
       "2499  survive surviving christmas thought television...    0.747156   \n",
       "\n",
       "      pred_label  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "2495           1  \n",
       "2496           0  \n",
       "2497           0  \n",
       "2498           0  \n",
       "2499           1  \n",
       "\n",
       "[2500 rows x 7 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_results_sample = train_sample.copy()\n",
    "log_reg_model_sample = LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
    "log_reg_model_sample.fit(train_x_tfidf_1_sample, train_y_sample)\n",
    "OPTIMAL_CUTOFF_PROB = 0.49791\n",
    "log_reg_results_sample['pred_proba'] = [lst[1] for lst in log_reg_model_sample.predict_proba(train_x_tfidf_1_sample)]\n",
    "\n",
    "log_reg_results_sample['pred_label'] = (log_reg_results_sample['pred_proba'] > OPTIMAL_CUTOFF_PROB).astype(int)\n",
    "log_reg_results_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Business Context\n",
    "\n",
    "\n",
    "One useful application area of our analysis is in the area of data driven movie direction. If movie producers can know beforehand, what factors lead to a positive sentiment among viewers (exemplified by high IMDB ratings), then they can better tailor their movie scripts to incorporate those themes. Let's explore this use case further below. \n",
    "\n",
    "To implement this use case, I do the following: \n",
    "- segement the predictions based on predicted sentiment (positive/negative) using the logistic regression model\n",
    "- build a Latent Dirichlet Analysis (LDA) topic model on the positive predicted and negative predicted reviews separately \n",
    "\n",
    "## Segment the predictions by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pred_reviews_sample = list(log_reg_results_sample[log_reg_results_sample['pred_label'] == 1]['preproc_text'].values)\n",
    "neg_pred_reviews_sample = list(log_reg_results_sample[log_reg_results_sample['pred_label'] == 0]['preproc_text'].values)\n",
    "pos_pred_reviews_sample = [review.split(\" \") for review in pos_pred_reviews_sample]\n",
    "neg_pred_reviews_sample = [review.split(\" \") for review in neg_pred_reviews_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LDA Topic Model\n",
    "\n",
    "We build the model using the `gensim` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dictionary (a mapping from a id to the actual word)\n",
    "dictionary_pos = gensim.corpora.Dictionary(pos_pred_reviews_sample)\n",
    "dictionary_neg = gensim.corpora.Dictionary(neg_pred_reviews_sample)\n",
    "#filter out words that are too common (>10% of the corpus), and too rare (appear less than 5 times)\n",
    "dictionary_pos.filter_extremes(no_below=5, no_above=0.1, keep_n=100000)\n",
    "dictionary_neg.filter_extremes(no_below=5, no_above=0.1, keep_n=100000)\n",
    "#convert each document in the corpus to a bag of words representation\n",
    "bow_corpus_pos = [dictionary_pos.doc2bow(doc) for doc in pos_pred_reviews_sample]\n",
    "bow_corpus_neg = [dictionary_neg.doc2bow(doc) for doc in neg_pred_reviews_sample]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a tfidf representation for each document, since the tfidf unigram feature set performs best with the logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the tfidf model\n",
    "from gensim import corpora, models\n",
    "tfidf_pos = models.TfidfModel(bow_corpus_pos)\n",
    "tfidf_neg = models.TfidfModel(bow_corpus_neg)\n",
    "corpus_tfidf_pos = tfidf_pos[bow_corpus_pos]\n",
    "corpus_tfidf_neg = tfidf_neg[bow_corpus_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some experimental iterations, we note that the best num_topics to look for is around 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.002*\"fun\" + 0.001*\"horror\" + 0.001*\"american\" + 0.001*\"music\" + 0.001*\"kid\" + 0.001*\"wonderful\" + 0.001*\"anyone\" + 0.001*\"remember\" + 0.001*\"reason\" + 0.001*\"seeing\"\n",
      "Topic: 1 Word: 0.001*\"war\" + 0.001*\"series\" + 0.001*\"funny\" + 0.001*\"sequence\" + 0.001*\"pretty\" + 0.001*\"tv\" + 0.001*\"che\" + 0.001*\"yet\" + 0.001*\"short\" + 0.001*\"worth\"\n",
      "Topic: 2 Word: 0.001*\"music\" + 0.001*\"comedy\" + 0.001*\"true\" + 0.001*\"song\" + 0.001*\"episode\" + 0.001*\"actress\" + 0.001*\"loved\" + 0.001*\"audience\" + 0.001*\"fun\" + 0.001*\"need\"\n",
      "Topic: 3 Word: 0.002*\"version\" + 0.001*\"funny\" + 0.001*\"favorite\" + 0.001*\"series\" + 0.001*\"book\" + 0.001*\"hard\" + 0.001*\"stanwyck\" + 0.001*\"paul\" + 0.001*\"house\" + 0.001*\"might\"\n",
      "Topic: 4 Word: 0.002*\"episode\" + 0.001*\"watched\" + 0.001*\"job\" + 0.001*\"human\" + 0.001*\"funny\" + 0.001*\"probably\" + 0.001*\"tell\" + 0.001*\"french\" + 0.001*\"word\" + 0.001*\"child\"\n"
     ]
    }
   ],
   "source": [
    "#run the LDA model, and identify topics\n",
    "lda_model_tfidf_pos = gensim.models.LdaMulticore(corpus_tfidf_pos, num_topics=5, id2word=dictionary_pos, \n",
    "                                                 passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf_pos.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topic: 0 Word: 0.002*\"fun\" + 0.001*\"horror\" + 0.001*\"american\" + 0.001*\"music\" + 0.001*\"kid\" + 0.001*\"wonderful\" + 0.001*\"anyone\" + 0.001*\"remember\" + 0.001*\"reason\" + 0.001*\"seeing\"\n",
    "- Topic: 1 Word: 0.001*\"war\" + 0.001*\"series\" + 0.001*\"funny\" + 0.001*\"sequence\" + 0.001*\"pretty\" + 0.001*\"tv\" + 0.001*\"che\" + 0.001*\"yet\" + 0.001*\"short\" + 0.001*\"worth\"\n",
    "- Topic: 2 Word: 0.001*\"music\" + 0.001*\"comedy\" + 0.001*\"true\" + 0.001*\"song\" + 0.001*\"episode\" + 0.001*\"actress\" + 0.001*\"loved\" + 0.001*\"audience\" + 0.001*\"fun\" + 0.001*\"need\"\n",
    "- Topic: 3 Word: 0.002*\"version\" + 0.001*\"funny\" + 0.001*\"favorite\" + 0.001*\"series\" + 0.001*\"book\" + 0.001*\"hard\" + 0.001*\"stanwyck\" + 0.001*\"paul\" + 0.001*\"house\" + 0.001*\"might\"\n",
    "- Topic: 4 Word: 0.002*\"episode\" + 0.001*\"watched\" + 0.001*\"job\" + 0.001*\"human\" + 0.001*\"funny\" + 0.001*\"probably\" + 0.001*\"tell\" + 0.001*\"french\" + 0.001*\"word\" + 0.001*\"child\"\n",
    "\n",
    "\n",
    "Topics present in the positive predicted reviews:\n",
    "- Topic 0: American horror movies with kids, and music\n",
    "- Topic 1: War series on TV that are short and have some humor \n",
    "- Topic 2: Musical comedies distributed as a series; where the actress feels loved and the audience has fun \n",
    "- Topic 3: Funny series that are based on a book with \n",
    "- Topic 4: Funny movies about jobs, children, and display a human, relatable element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.002*\"zombie\" + 0.002*\"may\" + 0.002*\"terrible\" + 0.002*\"ending\" + 0.001*\"music\" + 0.001*\"hour\" + 0.001*\"killer\" + 0.001*\"watched\" + 0.001*\"yet\" + 0.001*\"anyone\"\n",
      "Topic: 1 Word: 0.002*\"book\" + 0.002*\"performance\" + 0.002*\"series\" + 0.001*\"need\" + 0.001*\"dialogue\" + 0.001*\"moment\" + 0.001*\"child\" + 0.001*\"terrible\" + 0.001*\"kid\" + 0.001*\"casting\"\n",
      "Topic: 2 Word: 0.002*\"tv\" + 0.001*\"fan\" + 0.001*\"western\" + 0.001*\"wanted\" + 0.001*\"attempt\" + 0.001*\"money\" + 0.001*\"overall\" + 0.001*\"found\" + 0.001*\"move\" + 0.001*\"version\"\n",
      "Topic: 3 Word: 0.002*\"book\" + 0.001*\"terrible\" + 0.001*\"special\" + 0.001*\"dvd\" + 0.001*\"anyone\" + 0.001*\"kid\" + 0.001*\"found\" + 0.001*\"poorly\" + 0.001*\"annoying\" + 0.001*\"boring\"\n",
      "Topic: 4 Word: 0.002*\"boring\" + 0.002*\"comedy\" + 0.002*\"money\" + 0.001*\"friend\" + 0.001*\"hard\" + 0.001*\"laugh\" + 0.001*\"anyone\" + 0.001*\"rather\" + 0.001*\"moment\" + 0.001*\"ending\"\n"
     ]
    }
   ],
   "source": [
    "#build the negative review LDA model\n",
    "lda_model_tfidf_neg = gensim.models.LdaMulticore(corpus_tfidf_neg, num_topics=5, id2word=dictionary_neg, \n",
    "                                                 passes=2, workers=4)\n",
    "\n",
    "\n",
    "for idx, topic in lda_model_tfidf_neg.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topic: 0 Word: 0.002*\"zombie\" + 0.002*\"may\" + 0.002*\"terrible\" + 0.002*\"ending\" + 0.001*\"music\" + 0.001*\"hour\" + 0.001*\"killer\" + 0.001*\"watched\" + 0.001*\"yet\" + 0.001*\"anyone\"\n",
    "- Topic: 1 Word: 0.002*\"book\" + 0.002*\"performance\" + 0.002*\"series\" + 0.001*\"need\" + 0.001*\"dialogue\" + 0.001*\"moment\" + 0.001*\"child\" + 0.001*\"terrible\" + 0.001*\"kid\" + 0.001*\"casting\"\n",
    "- Topic: 2 Word: 0.002*\"tv\" + 0.001*\"fan\" + 0.001*\"western\" + 0.001*\"wanted\" + 0.001*\"attempt\" + 0.001*\"money\" + 0.001*\"overall\" + 0.001*\"found\" + 0.001*\"move\" + 0.001*\"version\"\n",
    "- Topic: 3 Word: 0.002*\"book\" + 0.001*\"terrible\" + 0.001*\"special\" + 0.001*\"dvd\" + 0.001*\"anyone\" + 0.001*\"kid\" + 0.001*\"found\" + 0.001*\"poorly\" + 0.001*\"annoying\" + 0.001*\"boring\"\n",
    "- Topic: 4 Word: 0.002*\"boring\" + 0.002*\"comedy\" + 0.002*\"money\" + 0.001*\"friend\" + 0.001*\"hard\" + 0.001*\"laugh\" + 0.001*\"anyone\" + 0.001*\"rather\" + 0.001*\"moment\" + 0.001*\"ending\"\n",
    "\n",
    "Topics present in the negative predicted reviews:\n",
    "- Topic 0: Zombie movies with terrible endings and killers in them \n",
    "- Topic 1: Movies with terrible casting for children with poor dialogue, based on books\n",
    "- Topic 2: Western movies involving money distributed on TV\n",
    "- Topic 3: Movies based on kids books distributed via DVD\n",
    "- Topic 4: Comedies involving money, friends, and plain endings\n",
    "\n",
    "**Please note that the above topic characterisations may changed with repeated reruns of the cell, since LDA results are sometimes variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "If given more time, some next steps I would take are:\n",
    "- Implement data augmentation techniques to make the classifier more robust to noise. One data augmentation technique I would consider is the Easy Data Augmentation technique for NLP. This is relevant because I sometimes sample the data to reduce running times, and might improve test performance for some of the models.\n",
    "- Investigate the neural network based approaches (including perhaps attention mechanisms) since they are driving the state of the art in NLP.\n",
    "- Investigate other topic models other than LDA. Perhaps, conduct a clustering analysis on the word vector representations? One drawback of LDa is that the topics extracted aren't stable; they tend to change from run to run. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
